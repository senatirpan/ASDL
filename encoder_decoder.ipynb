{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-07 11:13:08.683257: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define encoder and decoder layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(keras.layers.Layer):\n",
    "    def __init__(self, emb_dim, num_heads, hid_dim, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.attention = keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=emb_dim)\n",
    "        self.dropout1 = keras.layers.Dropout(dropout)\n",
    "        self.norm1 = keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dense1 = keras.layers.Dense(hid_dim, activation='relu')\n",
    "        self.dense2 = keras.layers.Dense(emb_dim)\n",
    "        self.dropout2 = keras.layers.Dropout(dropout)\n",
    "        self.norm2 = keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "    def call(self, inputs, training=True):\n",
    "        attention_output = self.attention(inputs, inputs)\n",
    "        attention_output = self.dropout1(attention_output, training=training)\n",
    "        attention_output = self.norm1(inputs + attention_output)\n",
    "\n",
    "        intermediate_output = self.dense1(attention_output)\n",
    "        intermediate_output = self.dense2(intermediate_output)\n",
    "        intermediate_output = self.dropout2(intermediate_output, training=training)\n",
    "        intermediate_output = self.norm2(attention_output + intermediate_output)\n",
    "\n",
    "        return intermediate_output\n",
    "\n",
    "\n",
    "class DecoderLayer(keras.layers.Layer):\n",
    "    def __init__(self, emb_dim, num_heads, hid_dim, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.attention1 = keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=emb_dim)\n",
    "        self.dropout1 = keras.layers.Dropout(dropout)\n",
    "        self.norm1 = keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.attention2 = keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=emb_dim)\n",
    "        self.dropout2 = keras.layers.Dropout(dropout)\n",
    "        self.norm2 = keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dense1 = keras.layers.Dense(hid_dim, activation='relu')\n",
    "        self.dense2 = keras.layers.Dense(emb_dim)\n",
    "        self.dropout3 = keras.layers.Dropout(dropout)\n",
    "        self.norm3 = keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "    def call(self, inputs, encoder_outputs, training=True):\n",
    "        attention_output1 = self.attention1(inputs, inputs)\n",
    "        attention_output1 = self.dropout1(attention_output1, training=training)\n",
    "        attention_output1 = self.norm1(inputs + attention_output1)\n",
    "\n",
    "        attention_output2 = self.attention2(attention_output1, encoder_outputs)\n",
    "        attention_output2 = self.dropout2(attention_output2, training=training)\n",
    "        attention_output2 = self.norm2(attention_output1 + attention_output2)\n",
    "\n",
    "        intermediate_output = self.dense1(attention_output2)\n",
    "        intermediate_output = self.dense2(intermediate_output)\n",
    "        intermediate_output = self.dropout3(intermediate_output, training=training)\n",
    "        intermediate_output = self.norm3(attention_output2 + intermediate_output)\n",
    "\n",
    "        return intermediate_output\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define encoder and decoder models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(keras.layers.Layer):\n",
    "    def __init__(self, num_layers, emb_dim, num_heads, hid_dim, input_vocab_size, dropout):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.emb_dim = emb_dim\n",
    "        self.embedding = keras.layers.Embedding(input_vocab_size, emb_dim)\n",
    "        self.dropout = keras.layers.Dropout(dropout)\n",
    "        self.encoder_layers = [EncoderLayer(emb_dim, num_heads, hid_dim, dropout) for _ in range(num_layers)]\n",
    "\n",
    "    def call(self, inputs, training=True):\n",
    "        inputs = self.embedding(inputs)\n",
    "        inputs *= tf.math.sqrt(tf.cast(self.emb_dim, tf.float32))\n",
    "        inputs = self.dropout(inputs, training=training)\n",
    "\n",
    "        for encoder_layer in self.encoder_layers:\n",
    "            inputs = encoder_layer(inputs, training=training)\n",
    "\n",
    "        return inputs\n",
    "\n",
    "\n",
    "class Decoder(keras.layers.Layer):\n",
    "    def __init__(self, num_layers, emb_dim, num_heads, hid_dim, output_vocab_size, dropout):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.emb_dim = emb_dim\n",
    "        self.embedding = keras.layers.Embedding(output_vocab_size, emb_dim)\n",
    "        self.dropout = keras.layers.Dropout(dropout)\n",
    "        self.decoder_layers = [DecoderLayer(emb_dim, num_heads, hid_dim, dropout) for _ in range(num_layers)]\n",
    "\n",
    "    def call(self, inputs, encoder_outputs, training=True):\n",
    "        inputs = self.embedding(inputs)\n",
    "        inputs *= tf.math.sqrt(tf.cast(self.emb_dim, tf.float32))\n",
    "        inputs = self.dropout(inputs, training=training)\n",
    "\n",
    "        for decoder_layer in self.decoder_layers:\n",
    "            inputs = decoder_layer(inputs, encoder_outputs, training=training)\n",
    "\n",
    "        return inputs\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the EncoderDecoder model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class EncoderDecoder(keras.Model):\n",
    "    def __init__(self, num_layers, emb_dim, num_heads, hid_dim, input_vocab_size, output_vocab_size, dropout):\n",
    "        super(EncoderDecoder, self).__init__()\n",
    "\n",
    "        self.encoder = Encoder(num_layers, emb_dim, num_heads, hid_dim, input_vocab_size, dropout)\n",
    "        self.decoder = Decoder(num_layers, emb_dim, num_heads, hid_dim, output_vocab_size, dropout)\n",
    "        self.final_dense = keras.layers.Dense(output_vocab_size)\n",
    "\n",
    "    def call(self, inputs, training=True):\n",
    "        encoder_outputs = self.encoder(inputs, training=training)\n",
    "        decoder_outputs = self.decoder(inputs, encoder_outputs, training=training)  # Use inputs instead of targets\n",
    "        final_outputs = self.final_dense(decoder_outputs)\n",
    "        return final_outputs\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the model for your input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 8s 8s/step - loss: 11.6223\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 8.3048\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 9.9040\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.5900\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.3483\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.3835\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 4.7936\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 4.9413\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.0525\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4.4536\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13503a460>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define your input data\n",
    "input_data = np.array([[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]])\n",
    "target_data = np.array([[11, 12, 13, 14, 15], [16, 17, 18, 19, 20]])\n",
    "\n",
    "# Define model hyperparameters\n",
    "num_layers = 2\n",
    "emb_dim = 32\n",
    "num_heads = 4\n",
    "hid_dim = 64\n",
    "input_vocab_size = 100\n",
    "output_vocab_size = 100\n",
    "dropout = 0.1\n",
    "\n",
    "# Create an instance of the EncoderDecoder model\n",
    "model = EncoderDecoder(num_layers, emb_dim, num_heads, hid_dim, input_vocab_size, output_vocab_size, dropout)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "\n",
    "# Train the model\n",
    "model.fit(input_data, target_data, epochs=10, batch_size=2)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check overfitting or underfitting by new input data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 711ms/step\n",
      "[[[-8.27740490e-01 -1.55389166e+00 -3.35158110e-01 -9.63812828e-01\n",
      "    1.11858284e+00 -2.11791079e-02 -8.62942636e-01  1.99557707e-01\n",
      "   -2.77550668e-01  2.97810942e-01  4.03611958e-01  1.64057410e+00\n",
      "    1.20691919e+00  1.60742998e+00  1.07484889e+00  5.69986105e-01\n",
      "    1.13409579e+00 -4.89958018e-01  7.66841650e-01  1.29768044e-01\n",
      "   -3.31402600e-01  1.11744978e-01 -5.56424707e-02 -1.29184353e+00\n",
      "   -6.95902407e-01 -1.30048144e+00  2.18241930e-01 -4.97535676e-01\n",
      "   -2.19486877e-02 -1.15205102e-01 -7.17603862e-01 -2.17971280e-01\n",
      "   -9.64068845e-02 -1.58504725e-01 -6.76932812e-01  5.80210984e-01\n",
      "   -5.33658862e-01 -4.40996259e-01 -1.09522903e+00 -4.04753566e-01\n",
      "   -9.63765621e-01  1.61780524e+00 -5.39909780e-01  4.63281944e-02\n",
      "    1.47211459e-02 -8.38227749e-01  3.38538200e-01  3.65014225e-01\n",
      "   -6.79947197e-01 -7.31582493e-02  3.88835371e-02  1.28456247e+00\n",
      "   -6.53105557e-01 -1.20700312e+00 -1.52032030e+00 -1.57009542e-01\n",
      "   -1.45438939e-01 -1.60966128e-01 -2.59902179e-01 -9.44886267e-01\n",
      "    3.14378381e-01 -3.10607404e-01  9.16849524e-02 -5.22889912e-01\n",
      "    2.55619317e-01 -4.16861176e-01 -1.32979476e+00 -3.38238895e-01\n",
      "    1.38756365e-01 -7.25649655e-01 -2.17022642e-01 -9.95918453e-01\n",
      "    4.28400695e-01 -3.00139129e-01  7.02408373e-01 -1.02332756e-01\n",
      "    5.51382959e-01 -5.19630790e-01 -8.77042413e-01 -6.93113327e-01\n",
      "   -7.13260651e-01  1.15395617e+00 -2.76118875e-01 -3.71406317e-01\n",
      "   -4.23106879e-01  5.38976550e-01 -1.95433295e+00 -8.17945719e-01\n",
      "   -1.14111722e+00 -4.62899923e-01 -1.09414065e+00 -1.81761280e-01\n",
      "   -6.54534936e-01 -4.79480416e-01  1.18978344e-01 -2.70259768e-01\n",
      "   -6.89698577e-01 -3.74418408e-01 -8.12447846e-01 -9.02136922e-01]\n",
      "  [-8.08214843e-01 -1.02997065e+00 -6.83295786e-01 -5.63246667e-01\n",
      "    1.21755302e+00 -1.94891870e-01 -4.11546946e-01 -1.33416981e-01\n",
      "    1.68044880e-01  7.47202396e-01  3.85260224e-01  1.49154890e+00\n",
      "    1.06396878e+00  2.35782075e+00  1.28365684e+00  1.14161229e+00\n",
      "    6.89305067e-01 -4.97944236e-01 -1.44080728e-01  3.14902246e-01\n",
      "   -5.41635096e-01 -1.02797754e-01 -2.62286663e-01 -1.39040577e+00\n",
      "   -6.81987107e-01 -1.67539978e+00  2.48514488e-01 -5.71244895e-01\n",
      "   -1.15794323e-01 -5.34227014e-01 -8.33176374e-01 -3.21068555e-01\n",
      "   -5.39811812e-02 -4.23345625e-01 -4.19227451e-01  4.16818976e-01\n",
      "   -8.24142247e-02  8.80828500e-02 -6.26474917e-01  2.35182382e-02\n",
      "   -7.74684787e-01  1.01811647e+00 -2.01706499e-01  1.01745792e-01\n",
      "   -2.09737003e-01 -9.93012190e-01 -3.60634252e-02  7.88044393e-01\n",
      "    8.43100101e-02  9.75324772e-03 -4.07378495e-01  4.63977605e-01\n",
      "   -6.38271451e-01 -1.10559058e+00 -1.13694084e+00 -6.09590828e-01\n",
      "   -7.17012703e-01 -7.45866299e-01 -2.32456982e-01 -7.00603426e-01\n",
      "    1.38647050e-01 -4.45750266e-01  1.21823199e-01 -5.72252035e-01\n",
      "    2.86427706e-01 -7.63851762e-01 -1.02460158e+00 -4.05340284e-01\n",
      "    8.65504563e-01 -6.44509375e-01 -4.79196608e-01 -1.05455732e+00\n",
      "    2.04561055e-01 -5.13819873e-01  2.22238705e-01 -3.95662546e-01\n",
      "    5.58285654e-01 -4.54004645e-01 -7.68938124e-01 -6.23855352e-01\n",
      "   -1.01741600e+00  6.12321973e-01 -3.61012012e-01 -1.28312215e-01\n",
      "   -2.57452577e-01  2.77988702e-01 -2.09579563e+00 -9.42700922e-01\n",
      "   -1.01575518e+00 -4.86267775e-01 -1.05922937e+00 -4.64373976e-01\n",
      "   -6.79279268e-01 -4.49301958e-01  4.10310835e-01 -7.27048099e-01\n",
      "   -8.42160881e-01 -9.52037051e-02 -5.40331662e-01 -3.50986153e-01]\n",
      "  [-1.23738682e+00 -9.20878053e-01 -6.85040474e-01 -1.13005722e+00\n",
      "    6.33391619e-01  7.51171410e-01 -2.16089576e-01 -5.45600355e-01\n",
      "    4.55695063e-01  1.55744529e+00  3.22944254e-01  1.59905362e+00\n",
      "    4.23466712e-01  2.26553535e+00  1.20897496e+00  1.00057375e+00\n",
      "    6.79103911e-01 -2.83204556e-01  4.14009869e-01  6.25888482e-02\n",
      "   -7.90908575e-01  2.31338844e-01 -2.37382680e-01 -7.53646433e-01\n",
      "   -4.27579105e-01 -1.02419877e+00  7.88139880e-01 -8.76145124e-01\n",
      "   -2.65322089e-01 -9.98093784e-01 -3.88714224e-01 -3.42994541e-01\n",
      "   -2.12623000e-01 -3.79186541e-01 -6.03762865e-01  2.48835608e-01\n",
      "   -6.71193659e-01 -3.33341777e-01 -5.52035511e-01 -3.55452657e-01\n",
      "   -7.97040224e-01  5.61818957e-01 -5.48337638e-01 -3.90120924e-01\n",
      "   -2.47860432e-01 -5.44003725e-01  2.86592066e-01  3.34035337e-01\n",
      "   -3.95318031e-01  1.29321992e-01 -2.06743702e-01  1.34524131e+00\n",
      "   -5.25005400e-01 -6.71539664e-01 -1.02928436e+00 -3.49580765e-01\n",
      "   -2.37132847e-01 -2.78583586e-01 -7.26968288e-01 -2.98860371e-01\n",
      "    6.18569776e-02 -6.94469810e-01  1.11301094e-02 -6.02958500e-01\n",
      "    1.57694697e-01 -5.34233570e-01 -1.43666852e+00 -3.06640178e-01\n",
      "    1.01239336e+00 -9.87688780e-01  1.00096129e-01 -8.72580767e-01\n",
      "   -3.43165219e-01 -8.58469129e-01  2.36551672e-01 -1.07402587e+00\n",
      "    8.61915231e-01 -5.77957332e-01 -1.24107695e+00 -6.11714363e-01\n",
      "   -3.61429393e-01  1.50483274e+00 -5.64203799e-01 -1.76804215e-01\n",
      "   -7.90444195e-01  7.02203885e-02 -1.89952171e+00 -7.17469871e-01\n",
      "   -1.27970302e+00 -8.91869605e-01 -1.21422267e+00 -3.02452832e-01\n",
      "   -7.97326028e-01 -4.99499768e-01  3.09563905e-01 -5.80684721e-01\n",
      "   -2.02605724e-01 -4.32995826e-01 -5.72126389e-01 -5.15843451e-01]\n",
      "  [-9.59015906e-01 -9.06783402e-01 -1.01431000e+00 -7.22621679e-01\n",
      "    5.11950627e-02  9.02266622e-01  7.69860923e-01 -3.01124752e-01\n",
      "    2.69587129e-01  1.46329999e+00 -1.15302205e-01  9.53077734e-01\n",
      "    4.08687502e-01  1.99588251e+00  1.59893048e+00  8.31662714e-01\n",
      "   -1.40011817e-01  1.89972356e-01 -3.33405584e-01  3.54094654e-01\n",
      "   -6.35903656e-01  1.07160494e-01 -7.31515884e-01 -1.17798698e+00\n",
      "   -8.22495103e-01 -1.72447574e+00  8.84062529e-01 -3.44222724e-01\n",
      "    1.50021017e-01 -1.18771362e+00  1.29945174e-01  1.97019055e-01\n",
      "    4.91358459e-01 -5.57664216e-01  2.03802973e-01  1.11116457e+00\n",
      "   -1.42852509e+00  5.57795882e-01 -5.09598851e-01 -8.16344678e-01\n",
      "   -2.90985852e-01  7.17338622e-01 -1.09677351e+00  4.01157081e-01\n",
      "   -9.35986280e-01 -4.74987686e-01 -1.97913691e-01  1.17116263e-02\n",
      "   -2.04181582e-01 -1.74068883e-02  2.36230180e-01  8.39844704e-01\n",
      "   -1.18721880e-01 -6.14626884e-01 -7.02434778e-01  2.18877584e-01\n",
      "   -9.77269232e-01 -8.06614578e-01 -7.04193294e-01 -1.54107422e-01\n",
      "   -2.60439664e-01 -1.48702748e-02 -6.83837663e-03 -1.22566581e+00\n",
      "    4.52376515e-01 -4.84056056e-01 -8.14536810e-01 -6.23512626e-01\n",
      "    1.08651400e+00 -7.40584850e-01  3.74461830e-01 -2.84904808e-01\n",
      "   -6.71751797e-02 -6.31261289e-01  7.99722597e-02 -4.71619457e-01\n",
      "    2.34015003e-01 -1.15322137e+00 -9.34442222e-01 -6.46722794e-01\n",
      "   -5.90910316e-01  1.07120252e+00 -1.37039885e-01  8.26791525e-01\n",
      "   -5.66359997e-01  2.60150954e-02 -1.23737919e+00 -7.96214581e-01\n",
      "   -9.47840571e-01 -7.46808112e-01 -1.38893020e+00 -2.24065587e-01\n",
      "   -8.37613121e-02 -3.47998798e-01  1.06849961e-01 -4.40418631e-01\n",
      "   -7.14409590e-01 -1.03883684e-01 -4.26210493e-01 -4.66464609e-01]\n",
      "  [-5.09563982e-01 -5.46813309e-01 -9.20032382e-01 -1.95151210e-01\n",
      "    4.42858219e-01  2.08912671e-01 -1.22960210e-02 -1.89374387e-01\n",
      "    1.74091086e-01  1.54234087e+00  2.32970029e-01  1.12623072e+00\n",
      "    3.44397336e-01  2.24507785e+00  1.56785583e+00  1.20630074e+00\n",
      "   -6.10587448e-02 -4.24076952e-02 -4.17879254e-01  4.58759278e-01\n",
      "   -1.01258957e+00  1.35453284e-01 -1.71381548e-01 -5.59371233e-01\n",
      "   -7.99303293e-01 -9.95805621e-01  2.87938379e-02 -6.53952599e-01\n",
      "   -3.90582055e-01 -1.36253154e+00 -5.37628651e-01  1.17472140e-02\n",
      "    1.81834385e-01 -9.50921625e-02 -3.12183887e-01  3.84271204e-01\n",
      "   -2.62824506e-01  3.44936639e-01 -7.77749062e-01 -2.58129686e-01\n",
      "   -6.61769569e-01  9.12847459e-01 -8.26514482e-01 -4.95939329e-02\n",
      "   -6.35766685e-01 -1.75638437e-01  3.58320847e-02  7.95311704e-02\n",
      "   -1.81697011e-02  4.54515785e-01 -6.38189837e-02  3.01686972e-01\n",
      "   -9.09110606e-01 -4.94688869e-01 -1.25063848e+00 -1.12112470e-01\n",
      "   -7.53227413e-01 -6.22398913e-01 -6.01670682e-01 -4.46248055e-01\n",
      "    1.03699170e-01 -3.10543031e-01 -2.07586840e-01 -6.02787971e-01\n",
      "   -1.45676494e-01 -3.17720562e-01 -9.88682151e-01 -2.75326878e-01\n",
      "    9.35605288e-01 -4.87994701e-01 -1.67804047e-01 -5.87844372e-01\n",
      "    8.10567960e-02 -8.61696780e-01  5.26230261e-02 -4.12547946e-01\n",
      "    3.60256940e-01 -7.68178105e-01 -6.73603356e-01 -2.62124777e-01\n",
      "   -8.26524377e-01  9.73567367e-01 -3.88743162e-01  1.96310073e-01\n",
      "   -6.90035820e-01  6.23485088e-01 -1.25671422e+00 -1.16322315e+00\n",
      "   -1.04171646e+00 -1.00739634e+00 -1.27184069e+00 -3.78347844e-01\n",
      "   -2.34728493e-02 -7.27345169e-01  7.49044791e-02 -1.73248410e-01\n",
      "   -9.15341452e-02 -4.22051668e-01 -1.68843403e-01 -6.94790184e-01]]\n",
      "\n",
      " [[-7.13208497e-01 -7.94811845e-01 -2.19485238e-01  2.26129234e-01\n",
      "    7.94633508e-01 -6.27334297e-01 -9.93695855e-01  1.04207344e-01\n",
      "    3.88209432e-01  2.63924778e-01  1.13526314e-01  5.42978883e-01\n",
      "    3.31678241e-01  1.56241477e+00 -4.49018061e-01  8.83642584e-02\n",
      "    2.11925149e+00 -4.63891149e-01  2.71034390e-01 -3.01354885e-01\n",
      "   -3.69992226e-01 -8.99401382e-02 -5.78333020e-01 -3.90873849e-01\n",
      "   -1.24645390e-01  3.40511262e-01 -2.09639296e-01 -2.90584832e-01\n",
      "   -1.56257474e+00  1.73056871e-01 -1.04156613e+00 -1.00834084e+00\n",
      "   -6.73547208e-01  2.50841171e-01 -8.98820281e-01  1.12466669e+00\n",
      "    1.34424880e-01 -9.04459000e-01 -4.49064493e-01 -4.60380882e-01\n",
      "   -1.92530251e+00  9.61620271e-01  7.65817706e-03  1.06588340e+00\n",
      "   -3.25782597e-01 -1.14074647e+00 -9.44532812e-01  9.19925749e-01\n",
      "   -1.53677329e-01  4.59145188e-01  4.33429144e-04  6.97367430e-01\n",
      "   -1.21662943e-02 -8.40231776e-01 -1.32628465e+00 -6.26919329e-01\n",
      "    1.35641387e-02 -4.41161871e-01  6.30185604e-02 -7.82743096e-01\n",
      "    6.41509891e-01 -1.22302139e+00 -7.25969970e-01 -3.47380154e-02\n",
      "    1.21243560e+00  3.12337369e-01 -8.94738197e-01 -7.65716791e-01\n",
      "   -6.94169343e-01 -2.48640358e-01 -2.07152545e-01 -1.21104050e+00\n",
      "    1.22832322e+00 -1.11466870e-02  6.03898168e-01 -1.84900969e-01\n",
      "    7.44719148e-01 -5.42100966e-01 -8.23161662e-01  4.35520321e-01\n",
      "   -4.24649939e-02 -2.96699200e-02 -5.43563426e-01  6.17604628e-02\n",
      "   -2.64220655e-01 -2.09070444e-01 -1.31947124e+00 -7.23669052e-01\n",
      "   -1.48531544e+00 -3.70673656e-01 -3.57866466e-01 -1.00131786e+00\n",
      "   -1.36560512e+00  2.77511448e-01 -8.09528977e-02 -4.05149996e-01\n",
      "    1.88915208e-02 -1.06110775e+00 -8.05677295e-01 -4.32090908e-01]\n",
      "  [-1.09326565e+00 -3.96961063e-01 -3.87491137e-01 -4.49170649e-01\n",
      "    1.63697481e-01  9.81227756e-02 -4.01461273e-01 -6.71249807e-01\n",
      "    3.54889780e-01  7.83453524e-01  2.97448248e-01  7.47052670e-01\n",
      "   -8.80539343e-02  2.43829370e+00  1.19605708e+00  1.05381846e+00\n",
      "    9.35678601e-01  1.12194228e+00  7.22976089e-01  7.49901533e-01\n",
      "   -1.35290757e-01  3.77217412e-01 -4.70635206e-01 -3.82734418e-01\n",
      "   -7.02562749e-01  2.26702727e-03 -6.02460444e-01  1.49528384e-01\n",
      "   -2.91461617e-01 -9.09305394e-01 -3.87152076e-01  2.42453068e-01\n",
      "   -1.14535475e+00 -6.61752224e-01 -5.34135997e-01 -2.69583225e-01\n",
      "   -2.25805193e-01  2.23495252e-02 -4.23289210e-01 -5.32343864e-01\n",
      "   -1.63419521e+00  2.44559973e-01  5.49032927e-01  2.33564958e-01\n",
      "   -1.50320083e-01 -3.78363222e-01 -1.00765504e-01  2.71588862e-01\n",
      "   -8.70671347e-02  7.38895088e-02  2.42140278e-01 -2.45379388e-01\n",
      "   -1.82165906e-01 -9.20409977e-01 -1.24518144e+00 -6.65412188e-01\n",
      "   -1.06432223e+00 -5.79539239e-01 -1.04348361e+00 -2.66156018e-01\n",
      "    2.47804999e-01 -1.08198178e+00 -1.69199472e-03 -4.99151126e-02\n",
      "    6.67263865e-01 -2.62310565e-01 -1.36408603e+00 -3.79849881e-01\n",
      "    9.20414388e-01 -1.26101263e-02 -5.32821655e-01 -3.55287284e-01\n",
      "   -9.04139578e-01  3.73956263e-01  1.20763138e-01 -1.34874392e+00\n",
      "    4.04334515e-01 -1.82096928e-01 -6.45909369e-01 -3.49669755e-01\n",
      "   -6.17083549e-01  7.91821837e-01 -7.91021049e-01  1.56733632e-01\n",
      "    2.69593507e-01  1.11511886e-01 -1.11119294e+00 -3.31097573e-01\n",
      "   -2.24820399e+00 -1.08927870e+00 -2.48838902e-01 -1.45710766e+00\n",
      "   -8.90982449e-01 -3.24031174e-01 -4.77917165e-01 -9.90713388e-02\n",
      "    6.48704350e-01 -1.16224051e+00 -2.02706769e-01  2.22501889e-01]\n",
      "  [-7.11436033e-01  1.56340435e-01 -5.92384696e-01 -1.12418008e+00\n",
      "    3.01603556e-01 -2.80040145e-01 -3.60599786e-01 -5.98303378e-01\n",
      "    2.20832214e-01  6.50815248e-01  1.34942010e-01  6.72329783e-01\n",
      "    1.64928064e-01  2.01966023e+00  1.16425741e+00  1.88372329e-01\n",
      "    1.21137595e+00  2.65643537e-01  1.47836053e+00  4.94501665e-02\n",
      "   -4.62740939e-03  3.89113724e-01 -7.20663965e-01 -1.55450553e-01\n",
      "   -7.09832907e-01  5.07700861e-01 -1.06743789e+00  5.79157531e-01\n",
      "   -5.13165236e-01  2.74747074e-01 -8.67680609e-01 -2.74735540e-01\n",
      "   -5.90324879e-01 -2.39438638e-01 -9.94111001e-01  5.21885157e-01\n",
      "    2.74987638e-01  3.82945091e-01 -5.48618913e-01 -6.79929972e-01\n",
      "   -9.48028207e-01  7.87482858e-01  9.61018622e-01  1.07854748e+00\n",
      "    2.68877484e-03 -9.40435767e-01 -7.03622758e-01  5.97458720e-01\n",
      "   -6.54753387e-01  1.75083160e-01 -3.31845522e-01  1.57778054e-01\n",
      "   -1.66737288e-01 -1.80337787e+00 -1.14979172e+00  2.58120567e-01\n",
      "   -7.90785551e-01 -4.91984785e-02 -2.62182444e-01 -6.01027966e-01\n",
      "    7.13211715e-01 -3.40280712e-01 -4.70990688e-01  4.97578859e-01\n",
      "    4.42317635e-01 -5.50016761e-01 -4.30793673e-01 -6.93111956e-01\n",
      "   -3.11264038e-01 -3.92388999e-01  1.68558583e-01 -1.10059154e+00\n",
      "   -1.10153414e-01  1.62117884e-01  4.86557901e-01 -1.01258039e+00\n",
      "   -4.38971341e-01 -2.73391068e-01 -8.38351786e-01  5.79234250e-02\n",
      "   -7.36087918e-01  3.86597395e-01 -2.70105362e-01 -4.84409541e-01\n",
      "   -2.33420804e-01 -2.86558330e-01 -4.62646484e-01 -6.36769056e-01\n",
      "   -1.37750673e+00 -6.75021112e-01 -6.51881874e-01 -1.25366533e+00\n",
      "    1.09879017e-01 -1.58658192e-01 -9.33178127e-01  6.67447150e-01\n",
      "    5.84689900e-02 -5.75318873e-01 -9.51230943e-01 -3.50327551e-01]\n",
      "  [-8.83657753e-01 -2.48538136e-01  1.26487508e-01 -1.24497545e+00\n",
      "    4.90230948e-01 -5.04811062e-03  2.27034599e-01 -7.49408364e-01\n",
      "    5.67158461e-01  4.08933669e-01  5.92860818e-01  5.91666758e-01\n",
      "    9.62373674e-01  1.11715949e+00  1.16144228e+00  3.35589528e-01\n",
      "    1.93494010e+00 -3.14210385e-01  5.34284055e-01  1.64093447e+00\n",
      "    5.66960514e-01 -1.54309794e-01 -8.17120492e-01 -1.14709508e+00\n",
      "   -1.40521812e+00 -1.13024318e+00  1.54413626e-01  1.25150338e-01\n",
      "   -2.01540381e-01 -1.53407663e-01 -1.52308953e+00 -5.76819241e-01\n",
      "   -6.50734782e-01  2.42471769e-02 -3.77474040e-01  4.13581133e-02\n",
      "    1.21805102e-01 -7.56630182e-01 -1.22390318e+00 -3.74711782e-01\n",
      "   -5.36554873e-01  6.21375203e-01  6.55255377e-01  1.85514271e-01\n",
      "   -9.01942402e-02 -8.38489652e-01 -9.40611243e-01  1.23139620e+00\n",
      "   -6.64421499e-01 -7.97043294e-02 -1.92512080e-01  5.13129473e-01\n",
      "   -5.02306700e-01 -1.93742847e+00 -1.05397618e+00 -5.02811596e-02\n",
      "    2.93316543e-01 -9.21417356e-01 -1.37122422e-01 -7.08130479e-01\n",
      "    6.68742418e-01 -4.78697419e-01 -3.47488344e-01 -5.15468776e-01\n",
      "    2.34517157e-01  1.76136762e-01 -1.34408247e+00 -8.86404634e-01\n",
      "    7.14806795e-01 -1.04713249e+00 -1.88366160e-01 -1.35084319e+00\n",
      "    4.28611562e-02 -3.53011549e-01  8.36409509e-01 -5.10564804e-01\n",
      "    5.54708838e-01 -4.61830765e-01 -9.73904610e-01 -8.64616632e-01\n",
      "   -1.05519485e+00  4.45849657e-01 -2.50565022e-01 -4.77669358e-01\n",
      "   -3.66670132e-01  1.44566283e-01 -1.17805398e+00 -3.22854102e-01\n",
      "   -1.13621771e+00 -2.74560809e-01 -8.88033509e-01 -4.33471650e-01\n",
      "   -5.70745111e-01 -6.10697567e-01 -2.20775545e-01  8.53830352e-02\n",
      "   -5.40002942e-01 -6.56559706e-01 -1.01763046e+00  1.74137697e-01]\n",
      "  [-7.40697861e-01 -4.71407413e-01 -7.21021295e-01 -1.82329804e-01\n",
      "    1.09340549e+00 -2.65419185e-01  1.27166092e-01 -3.69851768e-01\n",
      "   -3.79217088e-01  1.20735216e+00  4.78656441e-01  1.93305269e-01\n",
      "    2.13465482e-01  1.89412415e+00  4.61766392e-01  4.16516483e-01\n",
      "    1.35802257e+00 -4.06837836e-02 -7.19672218e-02  1.98213384e-01\n",
      "   -5.50764333e-03  3.66733670e-01 -6.88712656e-01 -5.08449912e-01\n",
      "   -6.85265541e-01 -5.43413520e-01 -7.12652564e-01  6.16631389e-01\n",
      "   -9.33693647e-01 -1.12393248e+00 -9.14659202e-01 -5.14961958e-01\n",
      "   -1.13726091e+00  9.33388114e-01 -9.47924972e-01  1.65189356e-01\n",
      "    4.94363070e-01 -5.52493155e-01 -6.43765748e-01 -4.10608590e-01\n",
      "   -9.80201900e-01  8.28959048e-01  4.43627715e-01  1.10055044e-01\n",
      "   -7.27519333e-01 -4.21444565e-01 -5.73977947e-01  7.12266028e-01\n",
      "    6.49896041e-02  5.47253825e-02 -9.14365709e-01 -1.80802166e-01\n",
      "   -8.76559258e-01 -6.06712937e-01 -8.05573344e-01 -3.33213657e-01\n",
      "   -6.19091213e-01 -1.11453652e+00 -6.86957777e-01 -8.73363972e-01\n",
      "    9.61111009e-01 -6.46299541e-01 -5.74655592e-01 -1.06732070e-01\n",
      "    3.35713297e-01 -2.03770399e-01 -7.62922883e-01 -1.52020335e+00\n",
      "    1.86207831e-01 -5.50241172e-01 -6.42380655e-01 -7.86575198e-01\n",
      "    1.20973483e-01 -2.78779596e-01  5.01930058e-01 -1.03151917e+00\n",
      "    7.16534443e-04 -6.60650134e-01 -3.91973317e-01  2.67675936e-01\n",
      "   -5.43548107e-01  6.28162622e-01 -3.96290779e-01  1.25110531e+00\n",
      "   -6.50076747e-01 -2.56988518e-02 -1.08017540e+00 -1.04072940e+00\n",
      "   -1.14938903e+00 -2.87085325e-01 -4.91498351e-01 -8.14787805e-01\n",
      "   -8.30010056e-01 -7.33407378e-01  1.93133671e-02 -4.50027645e-01\n",
      "   -2.55118936e-01 -1.16224194e+00 -3.22600812e-01  2.60973573e-01]]]\n"
     ]
    }
   ],
   "source": [
    "# New input data\n",
    "new_input_data = np.array([[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]])\n",
    "\n",
    "# Generate predictions using the trained model\n",
    "predictions = model.predict(new_input_data)\n",
    "\n",
    "# Print the predictions\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
